# Basic configuration for our connector
name=datasink-dist
connector.class=com.oracle.connect.sink.SqlDatabaseSinkConnector

# We can have parallelism here so we have two tasks!
tasks.max=1
topics=FILECONFINAL

# the input topic has a schema, so we enable schemas conversion here too
key.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=true
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=true

# JDBCSink connector specific configuration
# http://docs.confluent.io/3.2.0/connect/connect-jdbc/docs/sink_config_options.html

connector.class=com.oracle.connect.sink.SqlDatabaseSinkConnector
topic=FILECONFINAL
driverName=com.mysql.jdbc.Driver
dburl=jdbc:mysql://localhost:3306/sys
dbusername=root
dbpassword=test1234
dbtable=TransactionRecord
last.record.file.location=C:\\kafka_2.12-2.6.0\\myconnect\\offset.txt
batch.size=10

auto.create=true
auto.evolve=true